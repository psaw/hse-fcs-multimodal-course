{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzWpMk0BTfno"
      },
      "source": [
        "# ДЗ2. Мультимодальный адаптер к Qwen3-0.6B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOtDtoFXTmY5"
      },
      "source": [
        "**Описание задания**\n",
        "\n",
        "В этом задании вы подключите внешнюю модальность (аудио или изображение) к языковой модели Qwen3-0.6B через небольшой обучаемый адаптер. Веса Qwen и выбранного предобученного энкодера мы замораживаем, обучается только адаптер.\n",
        "\n",
        "Выберите один из треков:\n",
        "\n",
        "- Трек A (аудио → текст)\n",
        "\n",
        "Описываем аудио (AudioCaps) с помощью Qwen. Энкодер: `HuBERT` / `wav2vec2` / `Whisper Encoder`.\n",
        "\n",
        "- Трек B (изображение → текст)\n",
        "\n",
        "Описываем изображения (image captioning датасет) с помощью Qwen. Энкодер: любая vision-модель.\n",
        "\n",
        "**Задачи:**\n",
        "\n",
        "1.   Заморозить параметры `QWEN` и предобученного энкодера (аудио или vision).\n",
        "\n",
        "2.   Создать и обучить адаптер, который сжимает временную / пространственную размерность признаков и проецирует их в скрытое пространство `Qwen`.\n",
        "\n",
        "3.   Подготовить данные для обучения и валидации модели.\n",
        "\n",
        "4.   Реализовать и сравнить несколько стратегий пулинга в адаптере (например, сжатие временной размерности для аудио или пространственной - для изображений).\n",
        "\n",
        "5.   Использовать `BERTScore` для оценки качества модели на отложенном датасете.\n",
        "\n",
        "**Основные этапы задания**\n",
        "\n",
        "*   Подготовка данных: для \"аудио → текст\" загрузите датасет AudioCaps, если \"изображение → текст\", то загрузите датасет для image captioning (например, `Flickr8k`), обработайте данные и создайте DataLoader для батчевого обучения. Рекомендуется выполнить полную предобработку данных (прекомпьют), чтобы сократить время обработки на этапе обучения.\n",
        "*   Реализация адаптера: создайте класс, который сжимает последовательность векторов.\n",
        "*   Интеграция с `QWEN`: реализуйте обработку входов и передачу через `QWEN`.\n",
        "*   Обучение модели: настройте процесс обучения с использованием `Cross Entropy Loss` и teacher forcing.\n",
        "*   Оценка: вычислите BERTScore между сгенерированными и реальными текстами на валидационном датасете.\n",
        "\n",
        "> **Внимание!** Последующие ячейки с условиями оформлены (название классов и переменных, инструкциии и комментарии) в ключе работы по треку А (аудио → текст). Если вы выбираете работать с vision задачей, можете ориентироваться содержательно на представленные кодовые сниппеты, но видоизменять их под свою задачу."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ek97gBqjS9U"
      },
      "source": [
        "### Сеттинг"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jENUF19MYaAU",
        "outputId": "4b5d0c04-5ba2-4d30-bcd0-b892c8dfce0b"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers\n",
        "# !pip install datasets torchaudio\n",
        "# !pip install bert_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JbyKDHKueNBa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, Subset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoConfig,\n",
        "    Wav2Vec2Processor,\n",
        "    Wav2Vec2Model,\n",
        ")\n",
        "from datasets import load_dataset\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from bert_score import BERTScorer\n",
        "from tqdm import tqdm\n",
        "\n",
        "import soundfile as sf  # для загрузки .flac файлов\n",
        "\n",
        "from pathlib import Path  # для современной работы с путями\n",
        "import json\n",
        "\n",
        "# для красивого вывода\n",
        "import rich\n",
        "from rich.pretty import pprint as pprint\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMNWATzFYh67",
        "outputId": "cc5b8b5d-c26f-430d-9784-ab41c92ccf61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ8xbIDFkYy6"
      },
      "source": [
        "**Загрузка данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMH2kpEDbCmU"
      },
      "source": [
        "Если вы выбираете трек с аудио, используйте датасет `AudioCaps`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H-IwBsjZ8oBX"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audiocaps_test_new.tsv'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/val_texts.json'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/test_texts.json'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audiocaps_train.tsv'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audio'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audiocaps_train_fixed.tsv'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audiocaps_test.tsv'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audiocaps_val_new.tsv'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'audiocaps/audiocaps/audiocaps_val.tsv'</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audiocaps_test_new.tsv'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/val_texts.json'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/test_texts.json'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audiocaps_train.tsv'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audio'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audiocaps_train_fixed.tsv'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audiocaps_test.tsv'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audiocaps_val_new.tsv'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'audiocaps/audiocaps/audiocaps_val.tsv'\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# your code here\n",
        "# (╯°□°）╯︵ ┻━┻\n",
        "# Уже загружен из ДЗ1\n",
        "# !kaggle datasets download nickkar30/audiocaps\n",
        "\n",
        "DATA_ROOT = Path(\"./audiocaps/audiocaps\")\n",
        "pprint(list(DATA_ROOT.iterdir()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YGacOadeVci"
      },
      "source": [
        "### Задание 1. Создание и обучение AudioConvAdapter (3 балла)\n",
        "\n",
        "1. Загрузите модель **Qwen3-0.6B** и заморозьте её параметры.  \n",
        "2. Загрузите предобученный аудио-энкодер (параметры также должны быть заморожены). Вы можете выбрать одну из следующих моделей: **HuBERT**, **wav2vec2**, или **Whisper Encoder**. Учтите особенности выбранной модели:  \n",
        "   - Например, `wav2vec2-large-960h-lv60-self` использует `flash_attention`, которая работает только с GPU архитектуры Ampere и с типом данных float16. Это может вызвать сложности, если используется другое оборудование.  \n",
        "3. Реализуйте класс `AudioConvAdapter`, который уменьшает размерность последовательности аудио по времени и переводит её в текстовое пространство модели QWEN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "4tYDMIDwYkAz"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen3ForCausalLM(\n",
              "  (model): Qwen3Model(\n",
              "    (embed_tokens): Embedding(151936, 1024)\n",
              "    (layers): ModuleList(\n",
              "      (0-27): 28 x Qwen3DecoderLayer(\n",
              "        (self_attn): Qwen3Attention(\n",
              "          (q_proj): Linear(in_features=1024, out_features=2048, bias=False)\n",
              "          (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
              "          (o_proj): Linear(in_features=2048, out_features=1024, bias=False)\n",
              "          (q_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "          (k_norm): Qwen3RMSNorm((128,), eps=1e-06)\n",
              "        )\n",
              "        (mlp): Qwen3MLP(\n",
              "          (gate_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (up_proj): Linear(in_features=1024, out_features=3072, bias=False)\n",
              "          (down_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
              "          (act_fn): SiLUActivation()\n",
              "        )\n",
              "        (input_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen3RMSNorm((1024,), eps=1e-06)\n",
              "    (rotary_emb): Qwen3RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qwen_model_name = \"Qwen/Qwen3-0.6B\"\n",
        "qwen_tokenizer =  AutoTokenizer.from_pretrained(qwen_model_name) # your code here\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(qwen_model_name).to(device)\n",
        "\n",
        "for param in qwen_model.parameters():\n",
        "    param.requires_grad = False\n",
        "qwen_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "id": "4hEbt8GXFhaP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/yc-user/hse-fcs-multimodal-course/.venv/lib/python3.10/site-packages/transformers/configuration_utils.py:335: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Wav2Vec2Model(\n",
              "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
              "    (conv_layers): ModuleList(\n",
              "      (0): Wav2Vec2GroupNormConvLayer(\n",
              "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
              "        (activation): GELUActivation()\n",
              "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
              "      )\n",
              "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
              "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
              "        (activation): GELUActivation()\n",
              "      )\n",
              "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
              "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
              "        (activation): GELUActivation()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (feature_projection): Wav2Vec2FeatureProjection(\n",
              "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): Wav2Vec2Encoder(\n",
              "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
              "      (conv): ParametrizedConv1d(\n",
              "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
              "        (parametrizations): ModuleDict(\n",
              "          (weight): ParametrizationList(\n",
              "            (0): _WeightNorm()\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (padding): Wav2Vec2SamePadLayer()\n",
              "      (activation): GELUActivation()\n",
              "    )\n",
              "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (layers): ModuleList(\n",
              "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
              "        (attention): Wav2Vec2Attention(\n",
              "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (feed_forward): Wav2Vec2FeedForward(\n",
              "          (intermediate_dropout): Dropout(p=0.0, inplace=False)\n",
              "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# your code here\n",
        "# Инициализация аудио-энкодера wav2vec2\n",
        "audio_model_name = \"facebook/wav2vec2-base\"\n",
        "audio_encoder = Wav2Vec2Model.from_pretrained(audio_model_name).to(device)\n",
        "audio_processor = Wav2Vec2Processor.from_pretrained(audio_model_name)\n",
        "\n",
        "# Заморозка параметров wav2vec2\n",
        "for param in audio_encoder.parameters():\n",
        "    param.requires_grad = False\n",
        "audio_encoder.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ckqo6GCxcmfD"
      },
      "outputs": [],
      "source": [
        "#DONE: имплементируйте конструктор и метод forward. Добавьте необходимые аргументы в конструктор\n",
        "\n",
        "class AudioConvAdapter(nn.Module):\n",
        "    \"\"\"\n",
        "    Пример максимально упрощённого адаптера из 4 блоков:\n",
        "    relu(Conv1D(in, in)) -> Linear(in, hid) -> relu(Conv1D(hid, hid)) -> Linear(hid, qwen_in)\n",
        "    где in - размер аудио вектора\n",
        "    hid - скрытое состояние адаптера (hid > in)\n",
        "    qwen_in - размерность хиддена qwen\n",
        "      - первый Conv1D уменьшает число временных шагов (stride/pooling),\n",
        "      - затем Linear преобразует hidden_dim,\n",
        "      - потом снова Conv1D (доп. pooling),\n",
        "      - потом Linear подгоняет к нужной размерности.\n",
        "    Можно без линейных слоев увеличивать размерность, но получится больше параметров\n",
        "    Можете реализивать любую свою архитектуру.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        output_dim: int,\n",
        "        hidden_dim: int,\n",
        "        stride: int = 2,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        #DONE: your code here\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.stride = stride\n",
        "        self.proj_in = nn.Linear(input_dim, hidden_dim)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.proj_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: [B, T, input_dim] из wav2vec2\n",
        "        if x.dtype != torch.float32:\n",
        "            x = x.to(torch.float32)\n",
        "        #DONE: your code here\n",
        "        x = self.proj_in(x)          # [B, T, hidden_dim]\n",
        "        x = x.transpose(1, 2)        # [B, hidden_dim, T]  — для Conv1d\n",
        "        x = self.conv(x)             # [B, hidden_dim, T']\n",
        "        x = x.transpose(1, 2)        # [B, T', hidden_dim]\n",
        "        x = self.proj_out(x)         # [B, T', output_dim] = размерность Qwen\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gSzOFB4Wbtao"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1024\n",
            "768\n"
          ]
        }
      ],
      "source": [
        "qwen_hidden_size = qwen_model.config.hidden_size\n",
        "print(qwen_hidden_size)\n",
        "print(audio_encoder.config.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PoXrO9YFcs2W"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trainable parameters in adapter: 8130560\n"
          ]
        }
      ],
      "source": [
        "adapter_hidden_dim = 1024   # внутренняя размерность adapter\n",
        "audio_adapter = AudioConvAdapter(\n",
        "    input_dim=audio_encoder.config.hidden_size,\n",
        "    output_dim=qwen_hidden_size, \n",
        "    hidden_dim=adapter_hidden_dim\n",
        ").to(device)\n",
        "\n",
        "print(\"Trainable parameters in adapter:\", sum(p.numel() for p in audio_adapter.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoFhT78mpSGZ"
      },
      "source": [
        "### Задание 2. Подготовка данных (2 балла)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XGP_y2mFBxxl"
      },
      "outputs": [],
      "source": [
        "def fix_tsv_file(tsv_in, tsv_out):\n",
        "    with open(tsv_in, \"r\", encoding=\"utf-8\") as fin, open(tsv_out, \"w\", encoding=\"utf-8\") as fout:\n",
        "        for line in fin:\n",
        "            parts = line.split(\"\\t\")\n",
        "            if len(parts) > 4:\n",
        "                fixed_line = \"\\t\".join(parts[:3]) + \"\\t\" + \" \".join(parts[3:]).strip()\n",
        "                fout.write(fixed_line + \"\\n\")\n",
        "            else:\n",
        "                fout.write(line)\n",
        "\n",
        "fix_tsv_file(DATA_ROOT / \"audiocaps_train.tsv\",\n",
        "             DATA_ROOT / \"audiocaps_train_fixed.tsv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "rnlU_CsvWwV7"
      },
      "outputs": [],
      "source": [
        "class AudioCapsDataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        tsv_path: str,\n",
        "        root_dir: str,\n",
        "        max_audio_length: int = 16000 * 10,  # 10 секунд при 16kHz\n",
        "        target_sample_rate: int = 16000\n",
        "    ):\n",
        "        \"\"\"\n",
        "        tsv_path: путь к .tsv (train/val), содержащему столбцы: 'audio' и 'text'.\n",
        "        root_dir: корневая папка, содержащая файлы.\n",
        "        max_audio_length: ограничение по длине в сэмплах (обрезаем длинные аудио).\n",
        "        target_sample_rate: ожидаемая частота дискретизации.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.df = pd.read_csv(tsv_path, sep=\"\\t\")\n",
        "        self.root_dir = root_dir\n",
        "        self.max_audio_length = max_audio_length\n",
        "        self.target_sample_rate = target_sample_rate\n",
        "        # Кэшируем resample-операторы по исходной частоте, чтобы не создавать на каждом __getitem__\n",
        "        self._resamplers: dict[int, torchaudio.transforms.Resample] = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Реализуйте чтение обучаеющего примера.\n",
        "        # Обратите внимание, что частота дискретизации (Sample Rate) должна соотвествовать частоте, на которой обучался аудио энкодер.\n",
        "        # Для ускорения обучения можно заранее отресемплить и векторизовать аудио, чтобы не тратить компьюь при обучении.\n",
        "        # Для дебага наоборот, проще на лету, чтобы не ждать долгую стадию препроцессинга.\n",
        "        # В этой стадии можно ограничить длительность аудио, например, 10 сек\n",
        "        # return waveform, sr, caption\n",
        "        # return vectorized_audio, caption\n",
        "\n",
        "        # Загружаем через soundfile, т.к. он работает с .flac без torchcodec\n",
        "        waveform, sr = sf.read(\n",
        "            self.root_dir + \"/\" + self.df.iloc[idx][\"audio\"],\n",
        "            dtype='float32',\n",
        "            frames=self.max_audio_length\n",
        "        )\n",
        "\n",
        "        # Конвертируем в моно (если стерео)\n",
        "        if len(waveform.shape) > 1:\n",
        "            waveform = np.mean(waveform, axis=1)\n",
        "\n",
        "        # Ресемплируем на лету\n",
        "        if sr != self.target_sample_rate:\n",
        "            waveform_tensor = torch.from_numpy(waveform).unsqueeze(0)\n",
        "            # resampler создаём один раз на sr\n",
        "            if sr not in self._resamplers:\n",
        "                self._resamplers[sr] = torchaudio.transforms.Resample(sr, self.target_sample_rate)\n",
        "            resampler = self._resamplers[sr]\n",
        "            waveform = resampler(waveform_tensor).squeeze(0).numpy()\n",
        "            sr = self.target_sample_rate\n",
        "\n",
        "        return waveform, sr, self.df.iloc[idx][\"text\"]\n",
        "\n",
        "#реализуйте один из вариантов collate_fn для пайплайна с процессингом оффлайн или на лету\n",
        "\n",
        "def collate_fn(\n",
        "    batch: list[tuple[np.ndarray, int, str]], \n",
        "    audio_processor: Wav2Vec2Processor = audio_processor\n",
        "):\n",
        "    \"\"\"\n",
        "    batch: список из N элементов [(waveform_i, sr_i, caption_i), ...].\n",
        "    Делает единый вызов audio_processor(..., padding=\"longest\") для всего батча,\n",
        "    возвращает (audio_inputs, captions).\n",
        "    \"\"\"\n",
        "\n",
        "    # audio_inputs[\"input_values\"] => форма [B, T_max]\n",
        "    # audio_inputs[\"attention_mask\"] => форма [B, T_max]\n",
        "\n",
        "    waveforms = [b[0] for b in batch]\n",
        "    captions = [b[2] for b in batch]\n",
        "\n",
        "    audio_inputs = audio_processor(\n",
        "        waveforms,\n",
        "        sampling_rate=16000,\n",
        "        padding=\"longest\",\n",
        "        return_attention_mask=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    return audio_inputs, captions\n",
        "\n",
        "# def collate_fn(batch):\n",
        "#     \"\"\"\n",
        "#     batch: список из N элементов [(waveform_i, sr_i, caption_i), ...].\n",
        "#     Делает единый вызов audio_processor(..., padding=\"longest\") для всего батча,\n",
        "#     возвращает (audio_inputs, captions).\n",
        "#     \"\"\"\n",
        "\n",
        "#     # audio_inputs[\"input_values\"] => форма [B, T_max]\n",
        "#     # audio_inputs[\"attention_mask\"] => форма [B, T_max]\n",
        "\n",
        "#     return collate_fn(batch, audio_encoder)\n",
        "\n",
        "train_tsv = \"./audiocaps/audiocaps/audiocaps_train_fixed.tsv\"\n",
        "val_tsv   = \"./audiocaps/audiocaps/audiocaps_val_new.tsv\"\n",
        "\n",
        "root_dir = \"./audiocaps\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dhVAzKNExaze"
      },
      "outputs": [],
      "source": [
        "train_dataset = AudioCapsDataset(train_tsv, root_dir)\n",
        "val_dataset   = AudioCapsDataset(val_tsv, root_dir)\n",
        "# инициализируйте Data loader'ы\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn # your collate\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=4,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn # your collate\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdT63ULkxXIA",
        "outputId": "a0e46cfb-b204-4a6a-f5eb-f5c13ef0de52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_values.shape = torch.Size([4, 160000])\n",
            "attention_mask.shape = torch.Size([4, 160000])\n",
            "captions = ['Two adults are speaking to a crying infant in a reassuring way', 'A toilet is flushed', 'A man talks and tap some objects', 'DOG GROWLING WITH A MAN TALKING THEN THE DOG GROWLING LOUDER']\n"
          ]
        }
      ],
      "source": [
        "# Проверка\n",
        "\n",
        "for batch in train_loader:\n",
        "    audio_inputs, captions = batch\n",
        "    print(\"input_values.shape =\", audio_inputs[\"input_values\"].shape)  # [B, T_max]\n",
        "    print(\"attention_mask.shape =\", audio_inputs[\"attention_mask\"].shape)  # [B, T_max]\n",
        "    print(\"captions =\", captions)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IJPPyqspYeH"
      },
      "source": [
        "## Задание 3. Трейн QwenAudioDescription (3 балла)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJfYjomHc-wu"
      },
      "source": [
        "1. Напишите класс `QwenAudioDescriptionTrainer`, который будет включать в себя:\n",
        "   - Обучение адаптера (`train_one_epoch`).\n",
        "   - Валидацию (`validate`).\n",
        "   - Генерацию описания аудио (`generate`).\n",
        "2. Реализуйте процесс обучения, который объединяет аудио-эмбеддинги и текстовые токены, а затем передаёт их в QWEN для предсказания текстов.\n",
        "3. Используйте Cross Entropy Loss для оптимизации аудио-адаптера. Остальные параметры модели остаются замороженными.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создайте ID для специального токена [AUDIO]\n",
        "audio_token_id = qwen_tokenizer(\"[AUDIO]\", add_special_tokens=False)[\"input_ids\"][0]\n",
        "special_token_id = audio_token_id\n",
        "\n",
        "class QwenAudioDescriptionTrainer:\n",
        "    def __init__(self, qwen_model, qwen_tokenizer, audio_encoder, audio_adapter, lr=1e-4):\n",
        "        self.qwen_model = qwen_model\n",
        "        self.qwen_tokenizer = qwen_tokenizer\n",
        "        self.audio_encoder = audio_encoder\n",
        "        self.audio_adapter = audio_adapter\n",
        "\n",
        "        # Создайте оптимизатор Adam (только для audio_adapter)\n",
        "        self.optimizer = torch.optim.Adam(self.audio_adapter.parameters(), lr=lr)\n",
        "        # Скалер для смешанной точности для ускорения (включается только на CUDA)\n",
        "        self.scaler = torch.amp.GradScaler(\"cuda\", enabled=device.type == \"cuda\")\n",
        "        \n",
        "        # Убедимся, что есть pad_token\n",
        "        if self.qwen_tokenizer.pad_token_id is None:\n",
        "            self.qwen_tokenizer.pad_token_id = self.qwen_tokenizer.eos_token_id\n",
        "\n",
        "    def train_one_epoch(self, train_loader):\n",
        "        self.audio_adapter.train()\n",
        "        total_loss = 0.0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            audio_inputs, texts = batch  # (audio_inputs, список строк)\n",
        "\n",
        "            # *Прогните через audio_encoder (заморожен) без градиентов\n",
        "            audio_mask_raw = audio_inputs[\"attention_mask\"].to(device)  # [B, T_samples]\n",
        "            with torch.no_grad():\n",
        "                input_values = audio_inputs[\"input_values\"].to(device, non_blocking=True)\n",
        "                audio_out = self.audio_encoder(input_values, attention_mask=audio_mask_raw)\n",
        "                audio_hidden = audio_out.last_hidden_state              # [B, T_a, d_a]\n",
        "            \n",
        "            audio_mask_encoded = self.audio_encoder._get_feature_vector_attention_mask(\n",
        "                audio_hidden.shape[1], \n",
        "                audio_mask_raw\n",
        "            ).to(device)\n",
        "\n",
        "            # Токенизируйте текстовые данные\n",
        "            texts_tokens = self.qwen_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "            input_ids = texts_tokens.input_ids                          # [B, T_t]\n",
        "            text_mask = texts_tokens.attention_mask                     # [B, T_t]\n",
        "\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=device.type == \"cuda\"):\n",
        "                # Пропустите скрытые состояния через аудио-адаптер\n",
        "                audio_embed = self.audio_adapter(audio_hidden)    # [B, T_a', d_q]\n",
        "                audio_mask = audio_mask_encoded[:, ::4]\n",
        "                \n",
        "                text_embeds = self.qwen_model.model.embed_tokens(input_ids) # [B, T_t, d_q]\n",
        "                \n",
        "                # Соберите all_embeddings для модели cat(audio, text)\n",
        "                all_embeddings = torch.cat([audio_embed, text_embeds], dim=1) # [B, T_a'+T_t, d_q]\n",
        "                attn_mask = torch.cat([audio_mask, text_mask], dim=1)     # [B, T_a'+T_t]\n",
        "\n",
        "                # Таргетом являются лейблы текстовых токенов (описаний аудио)\n",
        "                labels = input_ids.clone()\n",
        "                ignore = torch.full((labels.size(0), audio_embed.size(1)), -100, device=device)\n",
        "                labels_full = torch.cat([ignore, labels], dim=1)\n",
        "\n",
        "                # Пропустите данные через модель QWEN и вычислите лосс\n",
        "                outputs = self.qwen_model(\n",
        "                    inputs_embeds=all_embeddings,\n",
        "                    attention_mask=attn_mask,\n",
        "                    labels=labels_full\n",
        "                )\n",
        "                loss = outputs.loss\n",
        "\n",
        "            # Выполните шаг оптимизации (со скалером)\n",
        "            self.optimizer.zero_grad()\n",
        "            self.scaler.scale(loss).backward()\n",
        "            self.scaler.step(self.optimizer)\n",
        "            self.scaler.update()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        return total_loss / len(train_loader)\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.audio_adapter.eval()\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "                audio_inputs, texts = batch  # (audio_inputs, список строк)\n",
        "\n",
        "                # *Прогните через audio_encoder (заморожен) без градиентов\n",
        "                input_values = audio_inputs[\"input_values\"].to(device, non_blocking=True)\n",
        "                audio_mask_raw = audio_inputs[\"attention_mask\"].to(device)  # [B, T_samples]\n",
        "                audio_out = self.audio_encoder(input_values, attention_mask=audio_mask_raw)\n",
        "                audio_hidden = audio_out.last_hidden_state              # [B, T_a, d_a]\n",
        "                \n",
        "                audio_mask_encoded = self.audio_encoder._get_feature_vector_attention_mask(\n",
        "                    audio_hidden.shape[1], \n",
        "                    audio_mask_raw\n",
        "                ).to(device)\n",
        "\n",
        "                with torch.amp.autocast(device_type=\"cuda\", enabled=device.type == \"cuda\"):\n",
        "                    # Пропустите скрытые состояния через аудио-адаптер\n",
        "                    audio_embed = self.audio_adapter(audio_hidden)    # [B, T_a', d_q]\n",
        "                    audio_mask = audio_mask_encoded[:, ::4]\n",
        "                    \n",
        "                    # Токенизируйте текстовые данные и примите QWEN эмбеддер\n",
        "                    texts_tokens = self.qwen_tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "                    input_ids = texts_tokens.input_ids                          # [B, T_t]\n",
        "                    text_mask = texts_tokens.attention_mask                     # [B, T_t]\n",
        "                    text_embeds = self.qwen_model.model.embed_tokens(input_ids) # [B, T_t, d_q]\n",
        "                    \n",
        "                    # Соберите all_embeddings для модели cat(audio, text)\n",
        "                    all_embeddings = torch.cat([audio_embed, text_embeds], dim=1) # [B, T_a'+T_t, d_q]\n",
        "                    attn_mask = torch.cat([audio_mask, text_mask], dim=1)     # [B, T_a'+T_t]\n",
        "\n",
        "                    # Таргетом являются лейблы текстовых токенов (описаний аудио)\n",
        "                    labels = input_ids.clone()\n",
        "                    ignore = torch.full((labels.size(0), audio_embed.size(1)), -100, device=device)\n",
        "                    labels_full = torch.cat([ignore, labels], dim=1)\n",
        "\n",
        "                    # Пропустите данные через модель QWEN и вычислите лосс\n",
        "                    outputs = self.qwen_model(\n",
        "                        inputs_embeds=all_embeddings,\n",
        "                        attention_mask=attn_mask,\n",
        "                        labels=labels_full\n",
        "                    )\n",
        "                    loss = outputs.loss\n",
        "\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        return val_loss / len(val_loader)\n",
        "\n",
        "    def generate(self, audio_inputs, max_new_tokens: int = 64, do_sample: bool = False, temperature: float = 1.0, top_p: float = 0.9):\n",
        "        self.audio_adapter.eval()\n",
        "        with torch.inference_mode():\n",
        "\n",
        "            # 1) input_values + attn_mask\n",
        "            input_values = audio_inputs[\"input_values\"].to(device, non_blocking=True)\n",
        "            audio_mask_raw = audio_inputs[\"attention_mask\"].to(device)\n",
        "\n",
        "            # 2) audio_encoder -> audio_adapter\n",
        "            audio_out = self.audio_encoder(input_values)\n",
        "            audio_hidden = audio_out.last_hidden_state\n",
        "            audio_mask_encoded = self.audio_encoder._get_feature_vector_attention_mask(\n",
        "                    audio_hidden.shape[1], \n",
        "                    audio_mask_raw\n",
        "            ).to(device)\n",
        "\n",
        "            # обернул в autocast для ускорения\n",
        "            with torch.amp.autocast(device_type=\"cuda\", enabled=device.type == \"cuda\"):\n",
        "                # Пропустите скрытые состояния через аудио-адаптер\n",
        "                audio_embed = self.audio_adapter(audio_hidden)    # [B, T_a', d_q]\n",
        "                audio_mask = audio_mask_encoded[:, ::4]\n",
        "                \n",
        "                # 3) Склейте audio_embeds + небольшой pseudo_input_ids\n",
        "                prompt = \"Summarize what you hear in the audio: \"\n",
        "                prompt_tokens = self.qwen_tokenizer(\n",
        "                    prompt,\n",
        "                    return_tensors=\"pt\",\n",
        "                    add_special_tokens=False,\n",
        "                )\n",
        "                prompt_input_ids = prompt_tokens.input_ids.to(device).expand(audio_embed.size(0), -1)\n",
        "                prompt_mask = prompt_tokens.attention_mask.to(device).expand(audio_embed.size(0), -1)\n",
        "                prompt_embed = self.qwen_model.model.embed_tokens(prompt_input_ids)\n",
        "\n",
        "                inputs_embeds = torch.cat([audio_embed, prompt_embed], dim=1)\n",
        "                attn_mask = torch.cat([audio_mask, prompt_mask], dim=1)\n",
        "\n",
        "                B = inputs_embeds.size(0)\n",
        "                audio_len = audio_embed.size(1)\n",
        "\n",
        "                # Заполняем часть под аудио специальными токенами и добавляем prompt\n",
        "                special_tokens = torch.full(\n",
        "                    (B, audio_len),\n",
        "                    special_token_id,\n",
        "                    device=device,\n",
        "                    dtype=torch.long,\n",
        "                )\n",
        "                input_ids = torch.cat([special_tokens, prompt_input_ids], dim=1)\n",
        "                # input_ids = input_ids.masked_fill(attn_mask == 0, self.qwen_tokenizer.pad_token_id)\n",
        "                \n",
        "                seq_len = input_ids.size(1)\n",
        "\n",
        "                # 4) Сгенерируйте текст\n",
        "                generated_ids = self.qwen_model.generate(\n",
        "                    input_ids=input_ids,\n",
        "                    inputs_embeds=inputs_embeds,\n",
        "                    attention_mask=attn_mask,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    do_sample=do_sample,\n",
        "                    temperature=temperature,\n",
        "                    top_p=top_p,\n",
        "                    pad_token_id=self.qwen_tokenizer.pad_token_id,\n",
        "                    eos_token_id=self.qwen_tokenizer.eos_token_id,\n",
        "                )\n",
        "\n",
        "            gen_text_ids = generated_ids[:, seq_len:]\n",
        "            generated_text = self.qwen_tokenizer.batch_decode(gen_text_ids, skip_special_tokens=True)\n",
        "        return generated_text\n",
        "\n",
        "    # Оценка модели по BERTScore\n",
        "    def evaluate_model(self, loader):\n",
        "        predictions = []\n",
        "        references = []\n",
        "        for batch in tqdm(loader, desc=\"Generating captions\"):\n",
        "            audio_inputs, texts = batch\n",
        "            preds = self.generate(audio_inputs)\n",
        "            predictions.extend(preds)\n",
        "            references.extend(texts)\n",
        "        \n",
        "        scorer = BERTScorer(lang=\"en\", model_type=\"bert-base-uncased\")\n",
        "        P, R, F1 = scorer.score(predictions, references)\n",
        "        \n",
        "        return predictions, references, P.mean(), R.mean(), F1.mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Рисует графики лоссов\n",
        "def plot_losses(t_loss, v_loss):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(t_loss, label='Train Loss')\n",
        "    plt.plot(v_loss, label='Validation Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Train and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Al6T5xqfWjA6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading last checkpoint...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 1547/1547 [08:38<00:00,  2.98it/s]\n",
            "Validating: 100%|██████████| 124/124 [00:10<00:00, 12.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/26, Train Loss: 1.0155, Val Loss: 2.2483, Best Val Loss: 2.1081, Best Epoch: 17\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# your code here\n",
        "# ┌(ಠ_ಠ)┘\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "LOAD_LAST_CHECKPOINT = True\n",
        "EPOCHS = 1\n",
        "EPOCH_START_NUMBER = 25\n",
        "\n",
        "ckpt_dir = Path(\"./checkpoints\")\n",
        "ckpt_dir.mkdir(parents=True, exist_ok=True)\n",
        "CKPT_NAME = \"hw2_audio_adapter_v2.pt\"\n",
        "train_loss = []\n",
        "val_loss = []\n",
        "best_val_loss = float('inf')\n",
        "best_epoch = 0\n",
        "\n",
        "trainer = QwenAudioDescriptionTrainer(qwen_model, qwen_tokenizer, audio_encoder, audio_adapter)\n",
        "\n",
        "# для продолжения обучения при разовых запусках\n",
        "if LOAD_LAST_CHECKPOINT and os.path.exists(ckpt_dir / CKPT_NAME):\n",
        "    print(\"Loading last checkpoint...\")\n",
        "    trainer.audio_adapter.load_state_dict(torch.load(ckpt_dir / CKPT_NAME))\n",
        "    losses = json.load(open(ckpt_dir / \"train_val_loss.json\"))\n",
        "    train_loss = losses[\"train_loss\"]\n",
        "    val_loss = losses[\"val_loss\"]\n",
        "    best_val_loss = min(val_loss)\n",
        "    best_epoch = val_loss.index(best_val_loss)\n",
        "\n",
        "\n",
        "# отдельный лоадер для лучших параметров (для NVIDIA A100)\n",
        "tmp_loader = DataLoader(\n",
        "    # Subset(train_dataset, range(320)),  # проверочный вариант\n",
        "    train_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn # your collate\n",
        ")\n",
        "\n",
        "\n",
        "if EPOCHS > 0:\n",
        "    for epoch in range(EPOCH_START_NUMBER, EPOCH_START_NUMBER + EPOCHS):\n",
        "        # обучаем\n",
        "        train_loss.append(trainer.train_one_epoch(tmp_loader))\n",
        "        # сохраняем\n",
        "        ckpt_path = Path(ckpt_dir / CKPT_NAME)\n",
        "        if ckpt_path.exists():\n",
        "            ckpt_path.rename(ckpt_path.with_suffix(f\".e{epoch-1:02d}.pt\"))\n",
        "        torch.save(trainer.audio_adapter.state_dict(), ckpt_dir / CKPT_NAME)\n",
        "        # валидируем\n",
        "        val = trainer.validate(val_loader)\n",
        "        val_loss.append(val)\n",
        "        # сохраняем лоссы\n",
        "        with open(ckpt_dir / \"train_val_loss.json\", \"w\") as f:\n",
        "            json.dump({\"train_loss\": train_loss, \"val_loss\": val_loss}, f)\n",
        "        if val < best_val_loss:\n",
        "            best_val_loss = val\n",
        "            best_epoch = epoch\n",
        "        print(f\"Epoch {epoch+1}/{EPOCH_START_NUMBER + EPOCHS}, Train Loss: {train_loss[-1]:.4f}, Val Loss: {val_loss[-1]:.4f}, Best Val Loss: {best_val_loss:.4f}, Best Epoch: {best_epoch}\")\n",
        "\n",
        "    # для накопления массива лоссов при разовых запусках\n",
        "    with open(ckpt_dir / \"train_val_loss.json\", \"w\") as f:\n",
        "        json.dump({\"train_loss\": train_loss, \"val_loss\": val_loss}, f)\n",
        "\n",
        "plot_losses(train_loss, val_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 803,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1st person speakingI am a student, 2nd person speaking, 3rd person speaking, 4th person speaking, 5th person speaking, 6th person speaking, 7th person speaking, 8th person speaking, 9th person speaking, 10th person speaking',\n",
              " '##############################################################',\n",
              " '2222222222222222222222222222222222222222222222222222222222222222',\n",
              " 'And then you hear the audio again. 2nd time. 3rd time. 4th time. 5th time. 6th time. 7th time. 8th time. 9th time. 10th time. 11th time. 12',\n",
              " '2You are listening to a car engine idling and a man is speaking in the background. The car engine idles and a man is speaking in the background. The car engine idles and a man is speaking in the background. The car engine idles and a man is speaking in the background. The car',\n",
              " '2222222222222222222222222222222222222222222222222222222222222222',\n",
              " 'I am in the background, and I am in the foreground, and I am in the middle, and I am in the middle, and I am in the middle, and I am in the middle, and I am in the middle, and I am in the middle, and I am in the middle, and',\n",
              " '2I am in the middle of a busy city, and I am walking by a bus. The bus is going by, and I am walking by. The bus is going by, and I am walking by. The bus is going by, and I am walking by. The bus is going by, and I',\n",
              " '2222222222222222222222222222222222222222222222222222222222222222',\n",
              " '2Who is the person speaking?Who is the person speaking? 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. ',\n",
              " '2222222222222222222222222222222222222222222222222222222222222222',\n",
              " '2I am in the middle of a forest, and I am walking by a stream. I am walking by a stream, and I am walking by a stream. I am walking by a stream. I am walking by a stream. I am walking by a stream. I am walking by a stream. I am',\n",
              " '1st and 2nd and 3rd and 4th and 5th and 6th and 7th and 8th and 9th and 10th and 11th and 12th and 13th and 14th and 15th',\n",
              " '1st person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person, 2nd person,',\n",
              " '3rd of the audio: 3rd of the audio: 3rd of the audio: 3rd of the audio: 3rd of the audio: 3rd of the audio: 3rd of the audio: 3rd of the audio: 3rd of the audio: 3',\n",
              " '1st person male speakingThe man speaks in the background. The man speaks in the background. The man speaks in the background. The man speaks in the background. The man speaks in the background. The man speaks in the background. The man speaks in the background. The man speaks in the background. The man']"
            ]
          },
          "execution_count": 803,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Пример генерации\n",
        "gen_loader = DataLoader(\n",
        "    Subset(train_dataset, range(160)),\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn # your collate\n",
        ")\n",
        "it = iter(gen_loader)\n",
        "trainer.generate(next(it)[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cabil9ZVpDiu"
      },
      "source": [
        "> Убедиться, что:\n",
        ">\n",
        "> При обучении лосс падает.\n",
        ">\n",
        "> При валидации всё аналогично, только без backward.\n",
        ">\n",
        ">  При генерации появляется текст (возможно, не самый качественный - это зависит от данных и количества эпох)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZfOOuuephD-"
      },
      "source": [
        "## Задание 4. Валидация (2 балла)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdPZsMIvr6-7"
      },
      "source": [
        "1. Используйте валидационный набор данных, чтобы проверить, насколько хорошо модель генерирует текстовые описания для аудио/картинок.\n",
        "\n",
        "2. Реализуйте процесс генерации текстов для всех аудио/картинок из валидационного набора.\n",
        "\n",
        "3. Используйте метрику **BERTScore** для оценки качества сгенерированных описаний.\n",
        "\n",
        "4. Отобразите примеры сгенерированных текстов и сравните их с истинными описаниями (references)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here (＠_＠)\n",
        "val_loader_big = DataLoader(\n",
        "    # Subset(train_dataset, range(320)),  # проверочный вариант\n",
        "    val_dataset,\n",
        "    batch_size=64,  # 64 для NVIDIA A100\n",
        "    shuffle=False,\n",
        "    num_workers=4,\n",
        "    pin_memory=True,\n",
        "    collate_fn=collate_fn # your collate\n",
        ")\n",
        "\n",
        "EVAL_EPOCH_START = 0\n",
        "EVAL_EPOCH_END = 25\n",
        "ckpt_path = Path(ckpt_dir / CKPT_NAME)\n",
        "all_predictions = []  # список списков сгенерированных текстов\n",
        "all_references = []  # список списков истинных текстов\n",
        "all_scores = []  # список словарей с метриками для каждой эпохи\n",
        "\n",
        "print(f\"Оценка всех сохраненных чекпоинтов: от {EVAL_EPOCH_START} до {EVAL_EPOCH_END}\")\n",
        "for epoch in range(EVAL_EPOCH_START, EVAL_EPOCH_END):\n",
        "    ckpt_path_val = ckpt_path.with_suffix(f\".e{epoch:02d}.pt\")\n",
        "    if ckpt_path_val.exists():\n",
        "        print(f\"Checkpoint {epoch}/{EVAL_EPOCH_END-1}\")\n",
        "        trainer.audio_adapter.load_state_dict(torch.load(ckpt_path_val))\n",
        "        predictions, references, P, R, F1 = trainer.evaluate_model(val_loader_big)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCH_START_NUMBER + EPOCHS}, BERTScore - Precision: {P.mean():.3f}, Recall: {R.mean():.3f}, F1: {F1.mean():.3f}\")\n",
        "        all_predictions.append(predictions)\n",
        "        all_references.append(references)\n",
        "        all_scores.append({\"P\": P.mean().item(), \"R\": R.mean().item(), \"F1\": F1.mean().item()})\n",
        "\n",
        "all_scores_df = pd.DataFrame(all_scores)\n",
        "\n",
        "# вывод удален, т.к. не имеет большой ценности и занимает много места"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Метрики для всех эпох обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>P</th>\n",
              "      <th>R</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.270897</td>\n",
              "      <td>0.314641</td>\n",
              "      <td>0.290029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.385436</td>\n",
              "      <td>0.460461</td>\n",
              "      <td>0.418219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.396182</td>\n",
              "      <td>0.460797</td>\n",
              "      <td>0.424733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.379776</td>\n",
              "      <td>0.431967</td>\n",
              "      <td>0.402103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.343291</td>\n",
              "      <td>0.402821</td>\n",
              "      <td>0.368768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.339093</td>\n",
              "      <td>0.401511</td>\n",
              "      <td>0.364922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.239216</td>\n",
              "      <td>0.328591</td>\n",
              "      <td>0.272488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.235492</td>\n",
              "      <td>0.328798</td>\n",
              "      <td>0.269595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.260613</td>\n",
              "      <td>0.346690</td>\n",
              "      <td>0.292591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.254679</td>\n",
              "      <td>0.341005</td>\n",
              "      <td>0.286948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.233236</td>\n",
              "      <td>0.319958</td>\n",
              "      <td>0.265494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.273233</td>\n",
              "      <td>0.354558</td>\n",
              "      <td>0.304833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.242202</td>\n",
              "      <td>0.321528</td>\n",
              "      <td>0.272605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.248385</td>\n",
              "      <td>0.327510</td>\n",
              "      <td>0.278899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.241050</td>\n",
              "      <td>0.328034</td>\n",
              "      <td>0.274168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.259009</td>\n",
              "      <td>0.339818</td>\n",
              "      <td>0.290422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.275121</td>\n",
              "      <td>0.359793</td>\n",
              "      <td>0.308362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.278149</td>\n",
              "      <td>0.355659</td>\n",
              "      <td>0.308193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.276746</td>\n",
              "      <td>0.364180</td>\n",
              "      <td>0.310694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.267423</td>\n",
              "      <td>0.351406</td>\n",
              "      <td>0.300054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.296397</td>\n",
              "      <td>0.377375</td>\n",
              "      <td>0.328836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.285815</td>\n",
              "      <td>0.375208</td>\n",
              "      <td>0.320519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.291850</td>\n",
              "      <td>0.380208</td>\n",
              "      <td>0.326693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.270933</td>\n",
              "      <td>0.359508</td>\n",
              "      <td>0.305129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.287207</td>\n",
              "      <td>0.375026</td>\n",
              "      <td>0.321238</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           P         R        F1\n",
              "0   0.270897  0.314641  0.290029\n",
              "1   0.385436  0.460461  0.418219\n",
              "2   0.396182  0.460797  0.424733\n",
              "3   0.379776  0.431967  0.402103\n",
              "4   0.343291  0.402821  0.368768\n",
              "5   0.339093  0.401511  0.364922\n",
              "6   0.239216  0.328591  0.272488\n",
              "7   0.235492  0.328798  0.269595\n",
              "8   0.260613  0.346690  0.292591\n",
              "9   0.254679  0.341005  0.286948\n",
              "10  0.233236  0.319958  0.265494\n",
              "11  0.273233  0.354558  0.304833\n",
              "12  0.242202  0.321528  0.272605\n",
              "13  0.248385  0.327510  0.278899\n",
              "14  0.241050  0.328034  0.274168\n",
              "15  0.259009  0.339818  0.290422\n",
              "16  0.275121  0.359793  0.308362\n",
              "17  0.278149  0.355659  0.308193\n",
              "18  0.276746  0.364180  0.310694\n",
              "19  0.267423  0.351406  0.300054\n",
              "20  0.296397  0.377375  0.328836\n",
              "21  0.285815  0.375208  0.320519\n",
              "22  0.291850  0.380208  0.326693\n",
              "23  0.270933  0.359508  0.305129\n",
              "24  0.287207  0.375026  0.321238"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_scores_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Примеры генерации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 798,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint 17:\n",
            "Example 23:\n",
            "Reference: Water flows and trickles\n",
            "Generated: 1I need to know the audio: 2. I need to know the audio: 3. I need to know the audio: 4. I need to know the audio: 5. I need to know the audio: 6. I need to know the audio: 7. I need\n",
            "Example 277:\n",
            "Reference: People talk quietly in the distance, followed by a police car siren wailing\n",
            "Generated: 2 people are talking, a vehicle is moving, and a person is speakingThe vehicle is moving, and a person is speaking. The vehicle is moving, and a person is speaking. The vehicle is moving, and a person is speaking. The vehicle is moving, and a person is speaking. The vehicle is moving\n",
            "Example 267:\n",
            "Reference: A motor runs in the distance as a soft wind periodically gusts\n",
            "Generated: 2You can hear the sound of a car engine idling and the wind blowing. The wind is blowing and the car engine is idling. The wind is blowing and the car engine is idling. The wind is blowing and the car engine is idling. The wind is blowing and the car engine is id\n",
            "Example 347:\n",
            "Reference: A dog growls then barks and whimpers\n",
            "Generated: I am a woman and I am talking to a man and then a dog barksI am a woman and I am talking to a man and then a dog barks and then a man laughs and then a dog barks and then a man laughs and then a dog barks and then a man laughs and\n",
            "Example 136:\n",
            "Reference: A woman speaks followed by another woman whimpering and speaking\n",
            "Generated: 2 people speakingI am a child and I am speaking to me, and I am making a sound of a child making a sound of a child making a sound of a child making a sound of a child making a sound of a child making a sound of a child making a sound of a child making a sound of\n",
            "Example 252:\n",
            "Reference: A fly buzzes around loudly as birds chirp\n",
            "Generated:  a person is speaking and a bird is chirpingThe person is speaking and a bird is chirping.  The person is speaking and a bird is chirping.  The person is speaking and a bird is chirping.  The person is speaking and a bird is chirping.  The person is speaking and\n",
            "Example 477:\n",
            "Reference: A horn is blown causing two babies to laugh and cheer loudly\n",
            "Generated: I am a baby crying and laughingI am a baby crying and laughing.I am a baby crying and laughing.I am a baby crying and laughing.I am a baby crying and laughing.I am a baby crying and laughing.I am a baby crying and laughing.I\n",
            "Example 278:\n",
            "Reference: A woman and man speak while food is frying\n",
            "Generated: 1st person is speaking, 2nd person is speaking, 3rd person is speaking, 4th person is speaking, 5th person is speaking, 6th person is speaking, 7th person is speaking, 8th person is speaking, 9th person is speaking, 1\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "i = 17\n",
        "print(f\"Checkpoint {i}:\")\n",
        "for j in random.sample(range(len(all_predictions[i])), 10):\n",
        "    if not re.search(r'[A-Za-zА-Яа-я]', all_predictions[i][j]):\n",
        "        continue  # пропускаем примеры, где нет буквенных символов\n",
        "    print(f\"Example {j+1}:\")\n",
        "    print(f\"Reference: {all_references[i][j]}\")\n",
        "    print(f\"Generated: {all_predictions[i][j]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Выводы\n",
        "\n",
        "На основе метрик от BERTScore из `all_scores_df` можно сделать следующие выводы:\n",
        "\n",
        "- Модель в целом научилась распознавать и описывать аудио.\n",
        "- Определяются различные аудио-паттерны, особенно хорошо:\n",
        "  - Голоса людей (speaking, talking)\n",
        "  - Звуки животных (лай собак, чириканье птиц)\n",
        "  - Природные звуки (свист ветра, журчание воды)\n",
        "  - Механические звуки (работа двигателей, сирены)\n",
        "- Странно, что лучшие результаты по метрикам достигнуты на эпохах 1-2 (F1 ~0.42, Precision ~0.39, Recall ~0.46)\n",
        "  - На ранних эпохах часто генерировалось одно и тоже для разных примеров, хотя это был связный текст. \n",
        "  - На более поздних - появилось много \"шума\" вида \"000000000000000000000\" и т.п. (одни цифры). Но если появлялся текст, то он чаще соответствал аудио.\n",
        "- Метрики стабилизировались на уровне F1 ~0.27-0.33, что указывает на необходимость дальнейшей оптимизации.\n",
        "- Модель склонна к повторениям в генерируемых текстах, что снижает качество описаний.\n",
        "\n",
        "В целом, модель демонстрирует прогресс в обучении и способность к базовому распознаванию аудио-паттернов, однако требует дальнейшей доработки для улучшения качества и точности генерируемых описаний.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BoFhT78mpSGZ"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
